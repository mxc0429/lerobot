# SmolVLA with RMT Memory Module - ä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•ä½¿ç”¨æ·»åŠ äº† RMT (Recurrent Memory Transformer) è®°å¿†æ¨¡å—çš„ SmolVLA æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ã€‚

## ğŸ¯ è®°å¿†æ¨¡å—ç‰¹æ€§

### æ–°å¢é…ç½®å‚æ•°

åœ¨ `SmolVLAConfig` ä¸­æ·»åŠ äº†ä»¥ä¸‹å‚æ•°ï¼š

```python
# RMT Memory settings
num_mem_tokens: int = 0          # è®°å¿† token æ•°é‡ (0=ç¦ç”¨, 4=æ¨è, 8=å¢å¼º)
mem_at_end: bool = False         # æ˜¯å¦åœ¨åºåˆ—æœ«å°¾ä¹Ÿæ·»åŠ è®°å¿† tokens
read_mem_from_cache: bool = False # è®°å¿† tokens æ˜¯å¦ä»ç¼“å­˜ä¸­è¯»å–
```

### å‚æ•°è¯´æ˜

- **num_mem_tokens**: 
  - `0`: ç¦ç”¨è®°å¿†æ¨¡å—ï¼ˆæ ‡å‡† SmolVLAï¼‰
  - `2`: è½»é‡çº§è®°å¿†ï¼ˆ+1,920 å‚æ•°ï¼Œ0.0004%ï¼‰
  - `4`: æ¨èé…ç½®ï¼ˆ+3,840 å‚æ•°ï¼Œ0.0009%ï¼‰
  - `8`: å¢å¼ºè®°å¿†ï¼ˆ+7,680 å‚æ•°ï¼Œ0.0017%ï¼‰
  - `16`: æœ€å¤§è®°å¿†ï¼ˆ+15,360 å‚æ•°ï¼Œ0.0034%ï¼‰

- **mem_at_end**: 
  - `False`: è®°å¿† tokens ä»…åœ¨åºåˆ—å¼€å¤´ï¼ˆæ¨èï¼‰
  - `True`: è®°å¿† tokens åœ¨å¼€å¤´å’Œç»“å°¾éƒ½æ·»åŠ 

- **read_mem_from_cache**: 
  - `False`: è®°å¿† tokens ä¸ä»å†å²ç¼“å­˜è¯»å–ï¼ˆæ¨èï¼‰
  - `True`: è®°å¿† tokens å¯ä»¥è®¿é—®å†å²è®°å¿†

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. è®­ç»ƒåŸºçº¿æ¨¡å‹ï¼ˆæ— è®°å¿†ï¼‰

```bash
# è®¾ç½®ä½ çš„ Hugging Face ç”¨æˆ·å
export HF_USER="your_username"

# è¿è¡ŒåŸºçº¿è®­ç»ƒ
bash train_baseline_smolvla.sh
```

æˆ–è€…ç›´æ¥ä½¿ç”¨å‘½ä»¤ï¼š

```bash
lerobot-train \
  --policy.path=./smolvla_base \
  --dataset.repo_id=${HF_USER}/pickplace_smolvla \
  --batch_size=4 \
  --output_dir=outputs/train/smolvla_baseline \
  --job_name=smolvla_baseline_training \
  --policy.push_to_hub=false \
  --policy.device=cuda \
  --wandb.enable=false \
  --policy.num_mem_tokens=0
```

### 2. è®­ç»ƒå¸¦è®°å¿†çš„æ¨¡å‹

```bash
# è¿è¡Œè®°å¿†å¢å¼ºè®­ç»ƒ
bash train_smolvla_with_memory.sh
```

æˆ–è€…ç›´æ¥ä½¿ç”¨å‘½ä»¤ï¼š

```bash
lerobot-train \
  --policy.path=./smolvla_base \
  --dataset.repo_id=${HF_USER}/pickplace_smolvla \
  --batch_size=4 \
  --output_dir=outputs/train/smolvla_with_memory_4tokens \
  --job_name=smolvla_memory_training \
  --policy.push_to_hub=false \
  --policy.device=cuda \
  --wandb.enable=false \
  --policy.num_mem_tokens=4 \
  --policy.mem_at_end=false \
  --policy.read_mem_from_cache=false
```

### 3. è¯„ä¼°å’Œå¯¹æ¯”æ¨¡å‹

```bash
python evaluate_models.py \
  --baseline_path outputs/train/smolvla_baseline/checkpoints/last/pretrained_model \
  --memory_path outputs/train/smolvla_with_memory_4tokens/checkpoints/last/pretrained_model \
  --dataset_repo_id ${HF_USER}/pickplace_smolvla \
  --n_episodes 50 \
  --output_file evaluation_results.json
```

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

è¯„ä¼°è„šæœ¬ä¼šæ¯”è¾ƒä»¥ä¸‹æŒ‡æ ‡ï¼š

1. **æˆåŠŸç‡ (Success Rate)**
   - ä»»åŠ¡å®Œæˆçš„ç™¾åˆ†æ¯”
   - è®°å¿†æ¨¡å—çš„ä¸»è¦æ”¹è¿›ç›®æ ‡

2. **å¹³å‡å¥–åŠ± (Average Reward)**
   - æ¯ä¸ª episode çš„å¹³å‡ç´¯ç§¯å¥–åŠ±
   - åæ˜ æ•´ä½“æ€§èƒ½

3. **æ¨ç†æ—¶é—´ (Inference Time)**
   - æ¯æ­¥åŠ¨ä½œé¢„æµ‹çš„æ—¶é—´
   - è¯„ä¼°è®¡ç®—å¼€é”€

4. **å†…å­˜ä½¿ç”¨ (Memory Usage)**
   - GPU å†…å­˜å ç”¨
   - è¯„ä¼°èµ„æºæ¶ˆè€—

## ğŸ”¬ å®éªŒé…ç½®å»ºè®®

### é…ç½® 1: å¿«é€ŸéªŒè¯
```bash
--policy.num_mem_tokens=2
--steps=10000
--batch_size=8
```
é€‚åˆå¿«é€ŸéªŒè¯è®°å¿†æ¨¡å—æ˜¯å¦æœ‰æ•ˆã€‚

### é…ç½® 2: æ ‡å‡†è®­ç»ƒï¼ˆæ¨èï¼‰
```bash
--policy.num_mem_tokens=4
--steps=50000
--batch_size=4
```
å¹³è¡¡æ€§èƒ½å’Œè®­ç»ƒæ—¶é—´çš„æ¨èé…ç½®ã€‚

### é…ç½® 3: å®Œæ•´è®­ç»ƒ
```bash
--policy.num_mem_tokens=4
--steps=200000
--batch_size=4
```
ç”¨äºè·å¾—æœ€ä½³æ€§èƒ½çš„å®Œæ•´è®­ç»ƒã€‚

### é…ç½® 4: å¢å¼ºè®°å¿†
```bash
--policy.num_mem_tokens=8
--steps=200000
--batch_size=4
```
ç”¨äºå¤æ‚çš„é•¿æœŸä»»åŠ¡ã€‚

## ğŸ“ˆ é¢„æœŸç»“æœ

åŸºäº RMT è®ºæ–‡çš„ç»“æœï¼Œé¢„æœŸæ”¹è¿›ï¼š

- **çŸ­æœŸä»»åŠ¡**: æˆåŠŸç‡æå‡ 1-3%
- **ä¸­æœŸä»»åŠ¡**: æˆåŠŸç‡æå‡ 3-5%
- **é•¿æœŸä»»åŠ¡**: æˆåŠŸç‡æå‡ 5-10%
- **æ¨ç†å¼€é”€**: < 2%
- **å†…å­˜å¼€é”€**: < 1%

## ğŸ” è°ƒè¯•å’Œç›‘æ§

### æ£€æŸ¥è®°å¿† tokens æ˜¯å¦æ­£å¸¸å·¥ä½œ

```python
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy

# åŠ è½½æ¨¡å‹
policy = SmolVLAPolicy.from_pretrained("path/to/checkpoint")

# æ£€æŸ¥è®°å¿† tokens
if policy.model.mem_tokens is not None:
    print(f"Memory tokens shape: {policy.model.mem_tokens.shape}")
    print(f"Memory tokens require grad: {policy.model.mem_tokens.requires_grad}")
else:
    print("Memory tokens are disabled")
```

### ç›‘æ§è®°å¿†çŠ¶æ€

```python
# åœ¨æ¨ç†è¿‡ç¨‹ä¸­
policy.reset()  # é‡ç½®è®°å¿†çŠ¶æ€

for step in range(num_steps):
    action = policy.select_action(batch)
    
    # æ£€æŸ¥è®°å¿†çŠ¶æ€
    if policy._mem_tokens_state is not None:
        print(f"Step {step}: Memory state shape = {policy._mem_tokens_state.shape}")
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### é—®é¢˜ 1: è®­ç»ƒæ—¶å†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**:
- å‡å°‘ `batch_size`
- å‡å°‘ `num_mem_tokens`
- ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯

```bash
--batch_size=2 \
--batch_chunk=2  # ç­‰æ•ˆäº batch_size=4
```

### é—®é¢˜ 2: è®°å¿†æ¨¡å—æ²¡æœ‰æ”¹è¿›

**å¯èƒ½åŸå› **:
1. ä»»åŠ¡ä¸éœ€è¦é•¿æœŸè®°å¿†
2. è®­ç»ƒæ­¥æ•°ä¸è¶³
3. è®°å¿† tokens æ•°é‡ä¸åˆé€‚

**è§£å†³æ–¹æ¡ˆ**:
- å¢åŠ è®­ç»ƒæ­¥æ•°
- å°è¯•ä¸åŒçš„ `num_mem_tokens` (2, 4, 8)
- æ£€æŸ¥ä»»åŠ¡æ˜¯å¦çœŸçš„éœ€è¦è®°å¿†

### é—®é¢˜ 3: æ¨ç†é€Ÿåº¦å˜æ…¢

**è§£å†³æ–¹æ¡ˆ**:
- å‡å°‘ `num_mem_tokens`
- ç¡®ä¿ `use_cache=True`
- ä½¿ç”¨ FP16 æ¨ç†

## ğŸ“ ä»£ç ä¿®æ”¹è¯´æ˜

### ä¸»è¦ä¿®æ”¹æ–‡ä»¶

1. **configuration_smolvla.py**
   - æ·»åŠ äº† `num_mem_tokens`, `mem_at_end`, `read_mem_from_cache` é…ç½®

2. **modeling_smolvla.py**
   - `VLAFlowMatching.__init__`: æ·»åŠ  `init_mem_tokens()` åˆå§‹åŒ–
   - `VLAFlowMatching.embed_prefix`: æ”¯æŒè®°å¿† tokens åµŒå…¥
   - `VLAFlowMatching.forward`: è¿”å›æ›´æ–°çš„è®°å¿† tokens
   - `VLAFlowMatching.sample_actions`: æ”¯æŒè®°å¿† tokens ä¼ é€’
   - `SmolVLAPolicy.reset`: é‡ç½®è®°å¿†çŠ¶æ€
   - `SmolVLAPolicy._get_action_chunk`: ç®¡ç†è®°å¿†çŠ¶æ€

### å‘åå…¼å®¹æ€§

æ‰€æœ‰ä¿®æ”¹éƒ½æ˜¯å‘åå…¼å®¹çš„ï¼š
- é»˜è®¤ `num_mem_tokens=0` æ—¶ï¼Œè¡Œä¸ºä¸åŸå§‹ SmolVLA å®Œå…¨ç›¸åŒ
- ç°æœ‰çš„è®­ç»ƒè„šæœ¬æ— éœ€ä¿®æ”¹å³å¯è¿è¡Œ

## ğŸ“ è¿›é˜¶ä½¿ç”¨

### è‡ªå®šä¹‰è®°å¿†åˆå§‹åŒ–

```python
# åœ¨ VLAFlowMatching.__init__ ä¸­
def init_mem_tokens(self):
    if self.config.num_mem_tokens == 0:
        self.mem_tokens = None
    else:
        hidden_size = self.vlm_with_expert.config.text_config.hidden_size
        
        # æ–¹æ³• 1: éšæœºåˆå§‹åŒ–ï¼ˆé»˜è®¤ï¼‰
        mem_tokens = torch.randn(self.config.num_mem_tokens, 1, hidden_size) * 0.02
        
        # æ–¹æ³• 2: é›¶åˆå§‹åŒ–
        # mem_tokens = torch.zeros(self.config.num_mem_tokens, 1, hidden_size)
        
        # æ–¹æ³• 3: ä»é¢„è®­ç»ƒåµŒå…¥åˆå§‹åŒ–
        # mem_tokens = self.vlm_with_expert.embed_language_tokens(
        #     torch.tensor([special_token_id] * self.config.num_mem_tokens)
        # )
        
        self.mem_tokens = nn.Parameter(mem_tokens, requires_grad=True)
```

### å¯è§†åŒ–è®°å¿†çŠ¶æ€

```python
import matplotlib.pyplot as plt
import seaborn as sns

def visualize_memory_evolution(policy, episode_data):
    """å¯è§†åŒ–è®°å¿† tokens åœ¨ episode ä¸­çš„æ¼”åŒ–"""
    memory_states = []
    
    policy.reset()
    for step_data in episode_data:
        action = policy.select_action(step_data)
        if policy._mem_tokens_state is not None:
            memory_states.append(policy._mem_tokens_state.cpu().numpy())
    
    # ç»˜åˆ¶çƒ­å›¾
    memory_array = np.array(memory_states)  # [steps, num_mem, batch, hidden]
    memory_norm = np.linalg.norm(memory_array, axis=-1).squeeze()
    
    plt.figure(figsize=(12, 6))
    sns.heatmap(memory_norm.T, cmap='viridis')
    plt.xlabel('Time Step')
    plt.ylabel('Memory Token')
    plt.title('Memory Token Evolution')
    plt.savefig('memory_evolution.png')
```

## ğŸ“š å‚è€ƒèµ„æ–™

- [RMT è®ºæ–‡](https://arxiv.org/abs/2207.06881): Recurrent Memory Transformer
- [SmolVLA è®ºæ–‡](https://huggingface.co/papers/2506.01844)
- [LeRobot æ–‡æ¡£](https://huggingface.co/docs/lerobot/index)

## ğŸ¤ è´¡çŒ®

å¦‚æœä½ å‘ç°é—®é¢˜æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼Œæ¬¢è¿æäº¤ Issue æˆ– Pull Requestã€‚

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ª Apache 2.0 è®¸å¯è¯ã€‚
