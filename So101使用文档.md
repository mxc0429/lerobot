

环境配置按照官网即可，克隆官网代码然后进行对应文件目录
git clone https://github.com/huggingface/lerobot.git
## 配置校准机械臂

```
终端执行 lerobot-find-port
示例输出如下，
Finding all available ports for the MotorBus.
['/dev/ttyACM0', '/dev/ttyACM1']
Remove the usb cable from your MotorsBus and press Enter when done.

[...Disconnect corresponding leader or follower arm and press Enter...]

The port of this MotorsBus is /dev/ttyACM0
Reconnect the USB cable.
修改端口权限
sudo chmod 666 /dev/ttyACM0
sudo chmod 666 /dev/ttyACM1
```

> [!NOTE]
>
> 先插上执行命令，然后拔掉以后按回车 。请记住要拔出 USB 接头，否则将无法检测到接口。

```
分别对主臂和从臂舵机进行编号，不要重复编号，已经编号过的跳过这一步
lerobot-setup-motors \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0
 lerobot-setup-motors \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM0   
```

```
校准机械臂，对每个关节进行校准，执行代码后将每个关节分别活动到最大和最小角度，主从臂活动范围尽可能一致，方便后续进行遥操作。
  python -m lerobot.calibrate \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \
    --robot.id=my_awesome_follower_arm
  python -m lerobot.calibrate \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM1 \
    --teleop.id=my_awesome_leader_arm
```

> [!NOTE]
>
> 端口号记得根据自己情况做出修改

## 进行机械臂遥操作

```
sudo chmod 666 /dev/ttyACM*
python -m lerobot.teleoperate \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \
    --robot.id=my_awesome_follower_arm \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM1 \
    --teleop.id=my_awesome_leader_arm
```

## 添加摄像头模块

```
#先检测摄像头设备
lerobot-find-cameras opencv # or realsense for Intel Realsense cameras
#类似输出
--- Detected Cameras ---
Camera #0:
  Name: OpenCV Camera @ 0
  Type: OpenCV
  Id: 0
  Backend api: AVFOUNDATION
  Default stream profile:
    Format: 16.0
    Width: 1920
    Height: 1080
    Fps: 15.0
--------------------
(more cameras ...)
在 ~/lerobot/outputs/captured_images中查看对应相机的图片和编号用于后续操作
lerobot-teleoperate \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \
    --robot.id=my_awesome_follower_arm \
    --robot.cameras="{
        camera1: {type: opencv, index_or_path: /dev/video4, width: 640, height: 480, fps: 30, fourcc: 'MJPG'},
        camera2: {type: opencv, index_or_path: /dev/video6, width: 640, height: 480, fps: 30, fourcc: 'MJPG'},
        camera3:{type: opencv, index_or_path: /dev/video2, width: 640, height: 480, fps: 30, fourcc: 'MJPG'}
    }" \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM1 \
    --teleop.id=my_awesome_leader_arm \
    --display_data=true
```

> [!TIP]
>
> 如果您有更多摄像头，可以通过更改 `--robot.cameras` 参数来添加。您应该注意`index_or_path` 的格式，它由 lerobot.find_cameras opencv’ 命令输出的摄像头 ID 的最后一位数字决定。

## 录制数据集

本地录制

```
lerobot-record \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \
    --robot.id=my_awesome_follower_arm \
     --robot.cameras="{
        base_0_rgb:       {type: opencv, index_or_path: /dev/video10, width: 640, height: 480, fps: 30, fourcc: 'MJPG'},
        left_wrist_0_rgb: {type: opencv, index_or_path: /dev/video4, width: 640, height: 480, fps: 30, fourcc: 'MJPG'},
        right_wrist_0_rgb:{type: opencv, index_or_path: /dev/video8, width: 640, height: 480, fps: 30, fourcc: 'MJPG'}
    }" \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM1 \
    --teleop.id=my_awesome_leader_arm \
    --display_data=true \
    --dataset.repo_id=Pickplace/test \
    --dataset.num_episodes=5 \
    --dataset.single_task="Grab the  cube" \
    --dataset.push_to_hub=false \
    --dataset.episode_time_s=2 \
    --dataset.reset_time_s=5 
    其中repo_id可以自定义修改，push_to_hub=false，最后数据集会保存在主目录的~/.cache/huggingface/lerobot下会创建上述seeedstudio123/test文件夹
```

云端录制

- 如果想使用 Hugging Face Hub 的功能来上传您的数据集，并且您之前尚未这样做，请确保您已使用具有写入权限的令牌登录，该令牌可以从 [Hugging Face 设置](https://huggingface.co/settings/tokens) 中生成：
- huggingface-cli login --token ${HUGGINGFACE_TOKEN} --add-to-git-credential




lerobot-record \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \
    --robot.id=my_awesome_follower_arm \
   --robot.cameras="{
        camera1: {type: opencv, index_or_path: /dev/video4, width: 640, height: 480, fps: 30, fourcc: 'MJPG'},
        camera2: {type: opencv, index_or_path: /dev/video6, width: 640, height: 480, fps: 30, fourcc: 'MJPG'},
        camera3:{type: opencv, index_or_path: /dev/video2, width: 640, height: 480, fps: 30, fourcc: 'MJPG'}
    }" \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM1 \
    --teleop.id=my_awesome_leader_arm \
    --display_data=true \
    --dataset.repo_id=${HF_USER}/pickplace_smolvla \
    --dataset.num_episodes=50 \
    --dataset.single_task="Pick and place the cube" \
    --dataset.push_to_hub=true \
    --dataset.episode_time_s=30 \
    --dataset.reset_time_s=8 
    
    出现类似数据
    INFO 2024-08-10 15:02:58 ol_robot.py:219 dt:33.34 (30.0hz) dtRlead: 5.06 (197.5hz) dtWfoll: 0.25 (3963.7hz) dtRfoll: 6.22 (160.7hz) dtRlaptop: 32.57 (30.7hz) dtRphone: 33.84 (29.5hz)
    如果记录过程中断，可以通过重新运行相同的命令并添加 --resume=true 来恢复记录。
```

> [!NOTE]
>
> **记录过程中的键盘控制**
>
> 使用键盘快捷键控制数据记录流程：
>
> | 键          | 动作                                   |
> | ----------- | -------------------------------------- |
> | →（右箭头） | 提前终止当前剧集/重置；进入下一个。    |
> | ←（左箭头） | 取消当前剧集；重新录制。               |
> | ESC         | 立即停止会话，编码视频，并上传数据集。 |
>
> **数据收集技巧**
>
> - **任务建议**：在不同位置抓取物体并将其放入箱子中。
>
> - **规模**：记录 ≥50 个剧集（每个位置 10 个剧集）。
>
> - 一致性
>
>   ：
>
>   - 保持摄像头固定。
>   - 保持相同的抓取行为。
>   - 确保操作的物体在摄像头画面中可见。
>
> - 逐步推进
>
>   ：
>
>   - 先从可靠的抓取开始，然后再增加变化（新位置、抓取技巧、摄像头调整）。
>   - 避免复杂性急剧增加，以防止失败。

## 回放数据集

```
lerobot-replay \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \
    --robot.id=my_awesome_follower_arm \
    --dataset.repo_id=${HF_USER}/record-test \
    --dataset.episode=0
```

## 训练

```
要训练一个控制您机器人策略，使用 python -m lerobot.scripts.train 脚本。需要一些参数。以下是一个示例命令：
lerobot-train \
  --dataset.repo_id=${HF_USER}/so101_pickplace_pi0_smolvla \
  --policy.type=act \
  --output_dir=outputs/train/act_so101_test2 \
  --job_name=act_so101_test \
  --policy.push_to_hub=false\
  --policy.device=cuda \
  --wandb.enable=false \
  --steps=300000 
  如果您想在本地数据集上进行训练，请确保 repo_id 与数据收集时使用的名称匹配，并添加 --policy.push_to_hub=false。
lerobot-train \
  --dataset.repo_id=${HF_USER}/pickplace_smolvla \
  --policy.type=act \
  --output_dir=outputs/train/act_train2 \
  --job_name=act_so101_test2 \
  --policy.device=cuda \
  --policy.push_to_hub=false\
  --wandb.enable=false \
  --steps=200000 \
  --policy.repo_id=${HF_USER}/act_pickplace_test 
  
 lerobot-train \
  --dataset.repo_id=${HF_USER}/so101_pickplace_pi0_smolvla \
  --policy.type=smolvla \
  --policy.repo_id=${HF_USER}/smolvla_so101_test2 \
  --output_dir=outputs/train/smolvla_so101_test2 \
  --job_name=smolvla_so101_test2 \
  --policy.device=cuda \
  --wandb.enable=false \
  --policy.push_to_hub=false\
  --steps=300000 
  
lerobot-train \
  --policy.type=pi0 \
  --policy.repo_id=${HF_USER}/pi0_so101_test \
  --dataset.repo_id=${HF_USER}/so101_pickplace_pi0_smolvla\
  --job_name=pi0_training \
  --output_dir=outputs/train/pi0_training \
  --policy.pretrained_path=./pi0_base \
  --policy.compile_model=true \
  --policy.gradient_checkpointing=true \
  --policy.dtype=bfloat16 \
  --policy.device=cuda \
  --batch_size=4 \
  --wandb.enable=false 
  
  ----------------------------------
lerobot-train \
  --policy.path=./smolvla_base \
  --dataset.repo_id=${HF_USER}/pickplace_smolvla\
  --batch_size=4 \
  --output_dir=outputs/train/smolvla_train2 \
  --job_name=my_smolvla_training \
  --policy.push_to_hub=false\
  --policy.device=cuda \
  --wandb.enable=false
  
  lerobot-train \
  --policy.type=pi05 \
  --policy.repo_id=${HF_USER}/pi0_so101_test \
  --dataset.repo_id=${HF_USER}/so101_pickplace_pi0_smolvla\
  --job_name=pi0_training \
  --output_dir=outputs/train/pi05_training \
  --policy.pretrained_path=./pi05_base \
  --policy.compile_model=true \
  --policy.gradient_checkpointing=true \
  --policy.dtype=bfloat16 \
  --policy.device=cuda \
  --batch_size=1 \
  --wandb.enable=false 
  
```

> [!NOTE]
>
> 命令解释
>
> - **数据集指定**：我们通过 `--dataset.repo_id=${HF_USER}/so101_test` 参数提供了数据集。
> - **训练步数**：我们通过 `--steps=300000` 修改训练步数，算法默认为800000，根据自己的任务难易程度，观察训练时候的loss来进行调整。
> - **策略类型**：我们使用 `policy.type=act` 提供了策略，同样你可以更换[act,diffusion,pi0,pi0fast,pi0fast,sac,smolvla]等策略，这将从 `configuration_act.py` 加载配置。重要的是，这个策略会自动适应您机器人（例如 `laptop` 和 `phone`）的电机状态、电机动作和摄像头数量，这些信息已保存在您的数据集中。
> - **设备选择**：我们提供了 `policy.device=cuda`，因为我们正在 Nvidia GPU 上进行训练，但您可以使用 `policy.device=mps` 在 Apple Silicon 上进行训练。
> - **可视化工具**：我们提供了 `wandb.enable=true` 来使用 [Weights and Biases](https://docs.wandb.ai/quickstart) 可视化训练图表。这是可选的，但如果您使用它，请确保您已通过运行 `wandb login` 登录。

## 评估

可以使用 [`lerobot/record.py`](https://github.com/huggingface/lerobot/blob/main/lerobot/record.py) 中的 `record` 功能，但需要将策略训练结果训练结果权重文件作为输入。例如，运行以下命令记录 10 个评估回合：

服务器ip=172.21.137.91使用服务器评估


```
lerobot-record \
  --robot.type=so101_follower \
  --robot.port=/dev/ttyACM0 \
  --robot.cameras="{
        camera1: {type: opencv, index_or_path: /dev/video6, width: 640, height: 480, fps: 30, fourcc: 'MJPG'},
        camera2: {type: opencv, index_or_path: /dev/video4, width: 640, height: 480, fps: 30, fourcc: 'MJPG'},
        camera3:{type: opencv, index_or_path: /dev/video2, width: 640, height: 480, fps: 30, fourcc: 'MJPG'}
    }" \
  --robot.id=my_awesome_follower_arm \
  --teleop.type=so101_leader\
  --teleop.port=/dev/ttyACM1\
  --teleop.id=my_awesome_leader_arm \
  --display_data=true \
  --dataset.repo_id=Eval/eval_act5 \
  --dataset.single_task="Pick and place the cube" \
  --policy.path=outputs/train/act_train/checkpoints/last/pretrained_model\
  --policy.device=cuda \
  --dataset.push_to_hub=false\
  --dataset.num_episodes=5 \
  --dataset.episode_time_s=30 \
  --dataset.reset_time_s=10
  
lerobot-record \
  --robot.type=so101_follower \
  --robot.port=/dev/ttyACM0 \
  --robot.cameras="{
        camera1: {type: opencv, index_or_path: /dev/video6, width: 640, height: 480, fps: 30, fourcc: 'MJPG'},
        camera2: {type: opencv, index_or_path: /dev/video4, width: 640, height: 480, fps: 30, fourcc: 'MJPG'},
        camera3:{type: opencv, index_or_path: /dev/video2, width: 640, height: 480, fps: 30, fourcc: 'MJPG'}
    }" \
  --robot.id=my_awesome_follower_arm \
  --teleop.type=so101_leader \
  --teleop.port=/dev/ttyACM1 \
  --teleop.id=my_awesome_leader_arm \
  --display_data=true \
  --dataset.repo_id=Eval/eval_act \
  --dataset.single_task="Pick the cube to place" \
  --policy.path=/home/cv502/.cache/huggingface/hub/models--mxc0429--act_pickplace/snapshots/1b49d3e3963400fa63ab78a1ec0422a181f41df3 \
  --policy.device=cuda \
  --dataset.push_to_hub=false \
  --dataset.num_episodes=5 \
  --dataset.episode_time_s=30 \
  --dataset.reset_time_s=10
  
  
```

> [!NOTE]
>
>   --policy.path 参数，指示您的策略训练结果权重文件的路径（例如 outputs/train/act_so101_test/checkpoints/last/pretrained_model）。如果您将模型训练结果权重文件上传到 Hub，也可以使用模型仓库（例如 ${HF_USER}/act_so100_test）。
>
> 数据集的名称dataset.repo_id以 eval_ 开头，这个操作会在你评估的时候为你单独录制评估时候的视频和数据，将保存在eval_开头的文件夹下，例如seeed/eval_test123。
>
> 如果评估阶段遇到File exists: 'home/xxxx/.cache/huggingface/lerobot/xxxxx/seeed/eval_xxxx'请先删除eval_开头的这个文件夹再次运行程序。
>
> 当遇到mean is infinity. You should either initialize with stats as an argument or use a pretrained model请注意--robot.cameras这个参数中的front和side等关键词必须和采集数据集的时候保持严格一致。

